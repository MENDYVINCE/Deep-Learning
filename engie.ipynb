{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cece0936",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T13:27:33.841175700Z",
     "start_time": "2026-01-07T13:27:33.055155400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hamza Laraisse\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from keras.optimizers import Adam\n",
    "from keras import layers, models , callbacks,losses ,regularizers\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d40c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = pd.read_csv( 'engie_X.csv',\n",
    "                   header    = 0,\n",
    "                   sep       = ';'\n",
    "                  )\n",
    "data_y = pd.read_csv('engie_Y.csv',\n",
    "                      header = 0,\n",
    "                      sep =';',\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a9105a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  TARGET\n",
       "0   1  -0.703\n",
       "1   2  -0.747\n",
       "2   3  -0.791\n",
       "3   4  -0.736\n",
       "4   5  -1.055"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a1b5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MAC_CODE', 'Date_time', 'Pitch_angle', 'Pitch_angle_min',\n",
       "       'Pitch_angle_max', 'Pitch_angle_std', 'Hub_temperature',\n",
       "       'Hub_temperature_min', 'Hub_temperature_max', 'Hub_temperature_std',\n",
       "       'Generator_converter_speed', 'Generator_converter_speed_min',\n",
       "       'Generator_converter_speed_max', 'Generator_converter_speed_std',\n",
       "       'Generator_speed', 'Generator_speed_min', 'Generator_speed_max',\n",
       "       'Generator_speed_std', 'Generator_bearing_1_temperature',\n",
       "       'Generator_bearing_1_temperature_min',\n",
       "       'Generator_bearing_1_temperature_max',\n",
       "       'Generator_bearing_1_temperature_std',\n",
       "       'Generator_bearing_2_temperature',\n",
       "       'Generator_bearing_2_temperature_min',\n",
       "       'Generator_bearing_2_temperature_max',\n",
       "       'Generator_bearing_2_temperature_std', 'Generator_stator_temperature',\n",
       "       'Generator_stator_temperature_min', 'Generator_stator_temperature_max',\n",
       "       'Generator_stator_temperature_std', 'Gearbox_bearing_1_temperature',\n",
       "       'Gearbox_bearing_1_temperature_min',\n",
       "       'Gearbox_bearing_1_temperature_max',\n",
       "       'Gearbox_bearing_1_temperature_std', 'Gearbox_bearing_2_temperature',\n",
       "       'Gearbox_bearing_2_temperature_min',\n",
       "       'Gearbox_bearing_2_temperature_max',\n",
       "       'Gearbox_bearing_2_temperature_std', 'Gearbox_inlet_temperature',\n",
       "       'Gearbox_inlet_temperature_min', 'Gearbox_inlet_temperature_max',\n",
       "       'Gearbox_inlet_temperature_std', 'Gearbox_oil_sump_temperature',\n",
       "       'Gearbox_oil_sump_temperature_min', 'Gearbox_oil_sump_temperature_max',\n",
       "       'Gearbox_oil_sump_temperature_std', 'Nacelle_angle',\n",
       "       'Nacelle_angle_min', 'Nacelle_angle_max', 'Nacelle_angle_std',\n",
       "       'Nacelle_temperature', 'Nacelle_temperature_min',\n",
       "       'Nacelle_temperature_max', 'Nacelle_temperature_std',\n",
       "       'Absolute_wind_direction', 'Outdoor_temperature',\n",
       "       'Outdoor_temperature_min', 'Outdoor_temperature_max',\n",
       "       'Outdoor_temperature_std', 'Grid_frequency', 'Grid_frequency_min',\n",
       "       'Grid_frequency_max', 'Grid_frequency_std', 'Grid_voltage',\n",
       "       'Grid_voltage_min', 'Grid_voltage_max', 'Grid_voltage_std',\n",
       "       'Rotor_speed', 'Rotor_speed_min', 'Rotor_speed_max', 'Rotor_speed_std',\n",
       "       'Rotor_bearing_temperature', 'Rotor_bearing_temperature_min',\n",
       "       'Rotor_bearing_temperature_max', 'Rotor_bearing_temperature_std',\n",
       "       'Absolute_wind_direction_c', 'Nacelle_angle_c'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x = data_x.drop(columns=['ID'])\n",
    "data_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be64a78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 617386 entries, 0 to 617385\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   ID      617386 non-null  int64  \n",
      " 1   TARGET  617386 non-null  float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 9.4 MB\n"
     ]
    }
   ],
   "source": [
    "data_y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6595419a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING VALUES :\n",
      "Grid_voltage                     16.411451\n",
      "Grid_voltage_min                 16.411451\n",
      "Grid_voltage_max                 16.411451\n",
      "Grid_voltage_std                 16.411451\n",
      "Generator_converter_speed         1.306152\n",
      "Generator_converter_speed_min     1.306152\n",
      "Gearbox_inlet_temperature_min     1.306152\n",
      "Gearbox_inlet_temperature         1.306152\n",
      "Generator_converter_speed_std     1.306152\n",
      "Generator_converter_speed_max     1.306152\n",
      "Gearbox_inlet_temperature_max     1.306152\n",
      "Gearbox_inlet_temperature_std     1.306152\n",
      "Absolute_wind_direction_c         0.011662\n",
      "Nacelle_angle_c                   0.011662\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_percentage = data_x.isna().mean() * 100\n",
    "\n",
    "print('MISSING VALUES :')\n",
    "if missing_percentage[missing_percentage != 0].empty:\n",
    "    print('No')\n",
    "else:\n",
    "    print(missing_percentage[missing_percentage != 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed86cde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MAC_CODE', 'Date_time', 'Pitch_angle', 'Pitch_angle_min',\n",
       "       'Pitch_angle_max', 'Pitch_angle_std', 'Hub_temperature',\n",
       "       'Hub_temperature_min', 'Hub_temperature_max', 'Hub_temperature_std',\n",
       "       'Generator_converter_speed', 'Generator_converter_speed_min',\n",
       "       'Generator_converter_speed_max', 'Generator_converter_speed_std',\n",
       "       'Generator_speed', 'Generator_speed_min', 'Generator_speed_max',\n",
       "       'Generator_speed_std', 'Generator_bearing_1_temperature',\n",
       "       'Generator_bearing_1_temperature_min',\n",
       "       'Generator_bearing_1_temperature_max',\n",
       "       'Generator_bearing_1_temperature_std',\n",
       "       'Generator_bearing_2_temperature',\n",
       "       'Generator_bearing_2_temperature_min',\n",
       "       'Generator_bearing_2_temperature_max',\n",
       "       'Generator_bearing_2_temperature_std', 'Generator_stator_temperature',\n",
       "       'Generator_stator_temperature_min', 'Generator_stator_temperature_max',\n",
       "       'Generator_stator_temperature_std', 'Gearbox_bearing_1_temperature',\n",
       "       'Gearbox_bearing_1_temperature_min',\n",
       "       'Gearbox_bearing_1_temperature_max',\n",
       "       'Gearbox_bearing_1_temperature_std', 'Gearbox_bearing_2_temperature',\n",
       "       'Gearbox_bearing_2_temperature_min',\n",
       "       'Gearbox_bearing_2_temperature_max',\n",
       "       'Gearbox_bearing_2_temperature_std', 'Gearbox_inlet_temperature',\n",
       "       'Gearbox_inlet_temperature_min', 'Gearbox_inlet_temperature_max',\n",
       "       'Gearbox_inlet_temperature_std', 'Gearbox_oil_sump_temperature',\n",
       "       'Gearbox_oil_sump_temperature_min', 'Gearbox_oil_sump_temperature_max',\n",
       "       'Gearbox_oil_sump_temperature_std', 'Nacelle_angle',\n",
       "       'Nacelle_angle_min', 'Nacelle_angle_max', 'Nacelle_angle_std',\n",
       "       'Nacelle_temperature', 'Nacelle_temperature_min',\n",
       "       'Nacelle_temperature_max', 'Nacelle_temperature_std',\n",
       "       'Absolute_wind_direction', 'Outdoor_temperature',\n",
       "       'Outdoor_temperature_min', 'Outdoor_temperature_max',\n",
       "       'Outdoor_temperature_std', 'Grid_frequency', 'Grid_frequency_min',\n",
       "       'Grid_frequency_max', 'Grid_frequency_std', 'Rotor_speed',\n",
       "       'Rotor_speed_min', 'Rotor_speed_max', 'Rotor_speed_std',\n",
       "       'Rotor_bearing_temperature', 'Rotor_bearing_temperature_min',\n",
       "       'Rotor_bearing_temperature_max', 'Rotor_bearing_temperature_std',\n",
       "       'Absolute_wind_direction_c', 'Nacelle_angle_c'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.drop(columns=['Grid_voltage','Grid_voltage_min','Grid_voltage_max','Grid_voltage_std'], inplace=True)\n",
    "data_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd8937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hamza Laraisse\\AppData\\Local\\Temp\\ipykernel_21160\\3960725246.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_x[col].fillna(data_x[col].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values replaced with mean successfully\n",
      "Remaining missing values:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    numeric_cols = data_x.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for col in numeric_cols:\n",
    "        if data_x[col].isnull().sum() > 0:\n",
    "            data_x[col].fillna(data_x[col].mean(), inplace=True)\n",
    "    \n",
    "    print(\"Missing values replaced with mean successfully\")\n",
    "    print(f\"Remaining missing values:\\n{data_x.isnull().sum().sum()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while replacing missing values: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3474d4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAC_CODE conversion complete:\n",
      "[3 2 4 1]\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "data_x['MAC_CODE'] = data_x['MAC_CODE'].map({'WT1': 1, 'WT2': 2, 'WT3': 3, 'WT4': 4})\n",
    "\n",
    "print(\"MAC_CODE conversion complete:\")\n",
    "print(data_x['MAC_CODE'].unique())\n",
    "print(data_x['MAC_CODE'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be2d79ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de X_train : (395126, 73)\n",
      "Dimensions de X_valid : (98782, 73)\n",
      "Dimensions de X_test  : (123478, 73)\n",
      "Dimensions de y_train : (395126,)\n",
      "Dimensions de y_valid : (98782,)\n",
      "Dimensions de y_test  : (123478,)\n"
     ]
    }
   ],
   "source": [
    "test_portion  = 1/5\n",
    "valid_portion = 1/5\n",
    "\n",
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(data_x, data_y['TARGET'], test_size=test_portion)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=valid_portion)\n",
    "\n",
    "print('Dimensions de X_train :', X_train.shape)\n",
    "print('Dimensions de X_valid :', X_valid.shape)\n",
    "print('Dimensions de X_test  :', X_test.shape)\n",
    "\n",
    "print('Dimensions de y_train :', y_train.shape)\n",
    "print('Dimensions de y_valid :', y_valid.shape)\n",
    "print('Dimensions de y_test  :', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c7d427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_valid_norm = scaler.transform(X_valid)\n",
    "X_test_norm  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ab4a484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"WindTurbine_DNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"WindTurbine_DNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,888</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m37,888\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN_3 (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN_4 (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">214,273</span> (837.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m214,273\u001b[0m (837.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">212,353</span> (829.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m212,353\u001b[0m (829.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim_inputs = X_train_norm.shape[1]\n",
    "\n",
    "model = models.Sequential(name='WindTurbine_DNN')\n",
    "\n",
    "# Input layer\n",
    "model.add(layers.Input(shape=(dim_inputs,), name='Input'))\n",
    "\n",
    "# First block - Large capacity\n",
    "model.add(layers.Dense(\n",
    "    512, \n",
    "    kernel_initializer='he_normal',\n",
    "    kernel_regularizer=regularizers.l2(0.0001),\n",
    "    name='Dense_1'\n",
    "))\n",
    "model.add(layers.BatchNormalization(name='BN_1'))\n",
    "model.add(layers.Activation('relu', name='Activation_1'))\n",
    "model.add(layers.Dropout(0.4, name='Dropout_1'))\n",
    "\n",
    "# Second block\n",
    "model.add(layers.Dense(\n",
    "    256,\n",
    "    kernel_initializer='he_normal',\n",
    "    kernel_regularizer=regularizers.l2(0.0001),\n",
    "    name='Dense_2'\n",
    "))\n",
    "model.add(layers.BatchNormalization(name='BN_2'))\n",
    "model.add(layers.Activation('relu', name='Activation_2'))\n",
    "model.add(layers.Dropout(0.3, name='Dropout_2'))\n",
    "\n",
    "# Third block\n",
    "model.add(layers.Dense(\n",
    "    128,\n",
    "    kernel_initializer='he_normal',\n",
    "    kernel_regularizer=regularizers.l2(0.0001),\n",
    "    name='Dense_3'\n",
    "))\n",
    "model.add(layers.BatchNormalization(name='BN_3'))\n",
    "model.add(layers.Activation('relu', name='Activation_3'))\n",
    "model.add(layers.Dropout(0.3, name='Dropout_3'))\n",
    "\n",
    "# Fourth block\n",
    "model.add(layers.Dense(\n",
    "    64,\n",
    "    kernel_initializer='he_normal',\n",
    "    kernel_regularizer=regularizers.l2(0.0001),\n",
    "    name='Dense_4'\n",
    "))\n",
    "model.add(layers.BatchNormalization(name='BN_4'))\n",
    "model.add(layers.Activation('relu', name='Activation_4'))\n",
    "model.add(layers.Dropout(0.2, name='Dropout_4'))\n",
    "\n",
    "# Fifth block\n",
    "#model.add(layers.Dense(\n",
    "#    32,\n",
    "#    kernel_initializer='he_normal',\n",
    "#    name='Dense_5'\n",
    "#))\n",
    "#model.add(layers.Activation('relu', name='Activation_5'))\n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Dense(1, activation='linear', name='Output'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b4e4d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.004),\n",
    "    loss='mae',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor='val_mae',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=10\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_mae',\n",
    "    factor=0.5,\n",
    "    patience=6,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    'best_wind_turbine_model.keras',\n",
    "    monitor='val_mae',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "240061b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_clipped = y_train.clip(lower=0)\n",
    "y_val_clipped   = y_valid.clip(lower=0)\n",
    "\n",
    "y_train_log = np.log1p(y_train_clipped)\n",
    "y_val_log   = np.log1p(y_val_clipped)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbfc8507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9373 - mae: 0.8328 - mse: 1.9753\n",
      "Epoch 1: val_mae improved from None to 0.28306, saving model to best_wind_turbine_model.keras\n",
      "\n",
      "Epoch 1: finished saving model to best_wind_turbine_model.keras\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.6359 - mae: 0.5601 - mse: 0.8485 - val_loss: 0.3284 - val_mae: 0.2831 - val_mse: 0.3410 - learning_rate: 0.0040\n",
      "Epoch 2/70\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5087 - mae: 0.4666 - mse: 0.5395\n",
      "Epoch 2: val_mae did not improve from 0.28306\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.5092 - mae: 0.4690 - mse: 0.5463 - val_loss: 0.4004 - val_mae: 0.3618 - val_mse: 0.4396 - learning_rate: 0.0040\n",
      "Epoch 3/70\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5039 - mae: 0.4669 - mse: 0.5452\n",
      "Epoch 3: val_mae did not improve from 0.28306\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.5017 - mae: 0.4657 - mse: 0.5415 - val_loss: 0.4133 - val_mae: 0.3778 - val_mse: 0.4203 - learning_rate: 0.0040\n",
      "Epoch 4/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5086 - mae: 0.4749 - mse: 0.5679\n",
      "Epoch 4: val_mae did not improve from 0.28306\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.5105 - mae: 0.4784 - mse: 0.5769 - val_loss: 0.3414 - val_mae: 0.3122 - val_mse: 0.3453 - learning_rate: 0.0040\n",
      "Epoch 5/70\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5042 - mae: 0.4751 - mse: 0.5756\n",
      "Epoch 5: val_mae improved from 0.28306 to 0.28246, saving model to best_wind_turbine_model.keras\n",
      "\n",
      "Epoch 5: finished saving model to best_wind_turbine_model.keras\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.5005 - mae: 0.4720 - mse: 0.5681 - val_loss: 0.3105 - val_mae: 0.2825 - val_mse: 0.3264 - learning_rate: 0.0040\n",
      "Epoch 6/70\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5031 - mae: 0.4743 - mse: 0.5713\n",
      "Epoch 6: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.5054 - mae: 0.4763 - mse: 0.5767 - val_loss: 0.3478 - val_mae: 0.3167 - val_mse: 0.3534 - learning_rate: 0.0040\n",
      "Epoch 7/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4906 - mae: 0.4602 - mse: 0.5461\n",
      "Epoch 7: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.4827 - mae: 0.4526 - mse: 0.5316 - val_loss: 0.4603 - val_mae: 0.4315 - val_mse: 0.6168 - learning_rate: 0.0040\n",
      "Epoch 8/70\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4685 - mae: 0.4394 - mse: 0.4953\n",
      "Epoch 8: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.4680 - mae: 0.4393 - mse: 0.4986 - val_loss: 0.4855 - val_mae: 0.4570 - val_mse: 0.7025 - learning_rate: 0.0040\n",
      "Epoch 9/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4593 - mae: 0.4323 - mse: 0.5006\n",
      "Epoch 9: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.4606 - mae: 0.4345 - mse: 0.5034 - val_loss: 0.4459 - val_mae: 0.4212 - val_mse: 0.6026 - learning_rate: 0.0040\n",
      "Epoch 10/70\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4544 - mae: 0.4303 - mse: 0.4911\n",
      "Epoch 10: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.4532 - mae: 0.4295 - mse: 0.4934 - val_loss: 0.5107 - val_mae: 0.4872 - val_mse: 0.6672 - learning_rate: 0.0040\n",
      "Epoch 11/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4483 - mae: 0.4250 - mse: 0.4861\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0020000000949949026.\n",
      "\n",
      "Epoch 11: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.4459 - mae: 0.4229 - mse: 0.4824 - val_loss: 0.4744 - val_mae: 0.4517 - val_mse: 0.6468 - learning_rate: 0.0040\n",
      "Epoch 12/70\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4271 - mae: 0.4053 - mse: 0.4398\n",
      "Epoch 12: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.4216 - mae: 0.4006 - mse: 0.4251 - val_loss: 0.4744 - val_mae: 0.4546 - val_mse: 0.7176 - learning_rate: 0.0020\n",
      "Epoch 13/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4124 - mae: 0.3928 - mse: 0.4081\n",
      "Epoch 13: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.4133 - mae: 0.3939 - mse: 0.4078 - val_loss: 0.4811 - val_mae: 0.4625 - val_mse: 0.7056 - learning_rate: 0.0020\n",
      "Epoch 14/70\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4094 - mae: 0.3907 - mse: 0.3985\n",
      "Epoch 14: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.4078 - mae: 0.3893 - mse: 0.3971 - val_loss: 0.5007 - val_mae: 0.4828 - val_mse: 0.8110 - learning_rate: 0.0020\n",
      "Epoch 15/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4093 - mae: 0.3913 - mse: 0.4018\n",
      "Epoch 15: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.4095 - mae: 0.3915 - mse: 0.3992 - val_loss: 0.4961 - val_mae: 0.4780 - val_mse: 0.7103 - learning_rate: 0.0020\n",
      "Epoch 16/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4049 - mae: 0.3869 - mse: 0.3894\n",
      "Epoch 16: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.4046 - mae: 0.3867 - mse: 0.3885 - val_loss: 0.4785 - val_mae: 0.4607 - val_mse: 0.7476 - learning_rate: 0.0020\n",
      "Epoch 17/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4045 - mae: 0.3866 - mse: 0.3908\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 17: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.4006 - mae: 0.3829 - mse: 0.3809 - val_loss: 0.4950 - val_mae: 0.4773 - val_mse: 0.7987 - learning_rate: 0.0020\n",
      "Epoch 18/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3905 - mae: 0.3734 - mse: 0.3635\n",
      "Epoch 18: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.3887 - mae: 0.3721 - mse: 0.3608 - val_loss: 0.5005 - val_mae: 0.4846 - val_mse: 0.8084 - learning_rate: 0.0010\n",
      "Epoch 19/70\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3855 - mae: 0.3698 - mse: 0.3547\n",
      "Epoch 19: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3822 - mae: 0.3668 - mse: 0.3487 - val_loss: 0.4624 - val_mae: 0.4474 - val_mse: 0.7085 - learning_rate: 0.0010\n",
      "Epoch 20/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3809 - mae: 0.3659 - mse: 0.3392\n",
      "Epoch 20: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.3791 - mae: 0.3642 - mse: 0.3361 - val_loss: 0.4415 - val_mae: 0.4268 - val_mse: 0.6858 - learning_rate: 0.0010\n",
      "Epoch 21/70\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3751 - mae: 0.3605 - mse: 0.3269\n",
      "Epoch 21: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.3746 - mae: 0.3601 - mse: 0.3270 - val_loss: 0.4738 - val_mae: 0.4595 - val_mse: 0.7402 - learning_rate: 0.0010\n",
      "Epoch 22/70\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3768 - mae: 0.3625 - mse: 0.3297\n",
      "Epoch 22: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.3750 - mae: 0.3605 - mse: 0.3260 - val_loss: 0.4872 - val_mae: 0.4727 - val_mse: 0.8184 - learning_rate: 0.0010\n",
      "Epoch 23/70\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3719 - mae: 0.3573 - mse: 0.3215\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.3718 - mae: 0.3572 - mse: 0.3216 - val_loss: 0.4414 - val_mae: 0.4268 - val_mse: 0.7030 - learning_rate: 0.0010\n",
      "Epoch 24/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3654 - mae: 0.3509 - mse: 0.3084\n",
      "Epoch 24: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.3629 - mae: 0.3487 - mse: 0.3051 - val_loss: 0.4519 - val_mae: 0.4381 - val_mse: 0.7350 - learning_rate: 5.0000e-04\n",
      "Epoch 25/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3580 - mae: 0.3444 - mse: 0.2941\n",
      "Epoch 25: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.3572 - mae: 0.3436 - mse: 0.2931 - val_loss: 0.4496 - val_mae: 0.4363 - val_mse: 0.7350 - learning_rate: 5.0000e-04\n",
      "Epoch 26/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3586 - mae: 0.3454 - mse: 0.2946\n",
      "Epoch 26: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.3557 - mae: 0.3425 - mse: 0.2899 - val_loss: 0.4559 - val_mae: 0.4430 - val_mse: 0.7426 - learning_rate: 5.0000e-04\n",
      "Epoch 27/70\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3565 - mae: 0.3436 - mse: 0.2910\n",
      "Epoch 27: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.3558 - mae: 0.3430 - mse: 0.2888 - val_loss: 0.4410 - val_mae: 0.4283 - val_mse: 0.7209 - learning_rate: 5.0000e-04\n",
      "Epoch 28/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3536 - mae: 0.3411 - mse: 0.2878\n",
      "Epoch 28: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.3530 - mae: 0.3405 - mse: 0.2858 - val_loss: 0.4461 - val_mae: 0.4338 - val_mse: 0.6982 - learning_rate: 5.0000e-04\n",
      "Epoch 29/70\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3527 - mae: 0.3404 - mse: 0.2861\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 29: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.3526 - mae: 0.3403 - mse: 0.2853 - val_loss: 0.4491 - val_mae: 0.4369 - val_mse: 0.7420 - learning_rate: 5.0000e-04\n",
      "Epoch 30/70\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3481 - mae: 0.3360 - mse: 0.2801\n",
      "Epoch 30: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.3471 - mae: 0.3350 - mse: 0.2773 - val_loss: 0.4290 - val_mae: 0.4171 - val_mse: 0.6945 - learning_rate: 2.5000e-04\n",
      "Epoch 31/70\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3460 - mae: 0.3342 - mse: 0.2777\n",
      "Epoch 31: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.3458 - mae: 0.3341 - mse: 0.2755 - val_loss: 0.4180 - val_mae: 0.4063 - val_mse: 0.6835 - learning_rate: 2.5000e-04\n",
      "Epoch 32/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3443 - mae: 0.3328 - mse: 0.2720\n",
      "Epoch 32: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.3443 - mae: 0.3328 - mse: 0.2733 - val_loss: 0.4277 - val_mae: 0.4164 - val_mse: 0.6902 - learning_rate: 2.5000e-04\n",
      "Epoch 33/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3413 - mae: 0.3300 - mse: 0.2660\n",
      "Epoch 33: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.3436 - mae: 0.3324 - mse: 0.2716 - val_loss: 0.4230 - val_mae: 0.4118 - val_mse: 0.7180 - learning_rate: 2.5000e-04\n",
      "Epoch 34/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3423 - mae: 0.3312 - mse: 0.2717\n",
      "Epoch 34: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.3424 - mae: 0.3314 - mse: 0.2704 - val_loss: 0.4319 - val_mae: 0.4209 - val_mse: 0.7068 - learning_rate: 2.5000e-04\n",
      "Epoch 35/70\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3407 - mae: 0.3298 - mse: 0.2658\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 35: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.3414 - mae: 0.3305 - mse: 0.2681 - val_loss: 0.4115 - val_mae: 0.4007 - val_mse: 0.6688 - learning_rate: 2.5000e-04\n",
      "Epoch 36/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3389 - mae: 0.3280 - mse: 0.2642\n",
      "Epoch 36: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.3392 - mae: 0.3284 - mse: 0.2651 - val_loss: 0.4211 - val_mae: 0.4104 - val_mse: 0.6825 - learning_rate: 1.2500e-04\n",
      "Epoch 37/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3386 - mae: 0.3279 - mse: 0.2639\n",
      "Epoch 37: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.3372 - mae: 0.3266 - mse: 0.2612 - val_loss: 0.4153 - val_mae: 0.4047 - val_mse: 0.6675 - learning_rate: 1.2500e-04\n",
      "Epoch 38/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3372 - mae: 0.3266 - mse: 0.2594\n",
      "Epoch 38: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.3368 - mae: 0.3263 - mse: 0.2600 - val_loss: 0.4195 - val_mae: 0.4091 - val_mse: 0.6539 - learning_rate: 1.2500e-04\n",
      "Epoch 39/70\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3381 - mae: 0.3276 - mse: 0.2646\n",
      "Epoch 39: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.3370 - mae: 0.3266 - mse: 0.2617 - val_loss: 0.4202 - val_mae: 0.4098 - val_mse: 0.6700 - learning_rate: 1.2500e-04\n",
      "Epoch 40/70\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3358 - mae: 0.3255 - mse: 0.2574\n",
      "Epoch 40: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.3363 - mae: 0.3260 - mse: 0.2598 - val_loss: 0.4201 - val_mae: 0.4099 - val_mse: 0.6693 - learning_rate: 1.2500e-04\n",
      "Epoch 41/70\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3363 - mae: 0.3261 - mse: 0.2627\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 41: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.3371 - mae: 0.3269 - mse: 0.2614 - val_loss: 0.4123 - val_mae: 0.4021 - val_mse: 0.6660 - learning_rate: 1.2500e-04\n",
      "Epoch 42/70\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3363 - mae: 0.3261 - mse: 0.2617\n",
      "Epoch 42: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.3349 - mae: 0.3248 - mse: 0.2589 - val_loss: 0.4102 - val_mae: 0.4001 - val_mse: 0.6577 - learning_rate: 6.2500e-05\n",
      "Epoch 43/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3319 - mae: 0.3219 - mse: 0.2533\n",
      "Epoch 43: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.3335 - mae: 0.3235 - mse: 0.2558 - val_loss: 0.4043 - val_mae: 0.3943 - val_mse: 0.6489 - learning_rate: 6.2500e-05\n",
      "Epoch 44/70\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3328 - mae: 0.3228 - mse: 0.2540\n",
      "Epoch 44: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.3330 - mae: 0.3230 - mse: 0.2550 - val_loss: 0.3956 - val_mae: 0.3856 - val_mse: 0.6281 - learning_rate: 6.2500e-05\n",
      "Epoch 45/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3325 - mae: 0.3225 - mse: 0.2536\n",
      "Epoch 45: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.3330 - mae: 0.3230 - mse: 0.2550 - val_loss: 0.4089 - val_mae: 0.3990 - val_mse: 0.6425 - learning_rate: 6.2500e-05\n",
      "Epoch 46/70\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3334 - mae: 0.3235 - mse: 0.2570\n",
      "Epoch 46: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3321 - mae: 0.3222 - mse: 0.2540 - val_loss: 0.4028 - val_mae: 0.3929 - val_mse: 0.6405 - learning_rate: 6.2500e-05\n",
      "Epoch 47/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3310 - mae: 0.3212 - mse: 0.2515\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 47: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3315 - mae: 0.3216 - mse: 0.2523 - val_loss: 0.3968 - val_mae: 0.3870 - val_mse: 0.6292 - learning_rate: 6.2500e-05\n",
      "Epoch 48/70\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3327 - mae: 0.3229 - mse: 0.2543\n",
      "Epoch 48: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3318 - mae: 0.3220 - mse: 0.2522 - val_loss: 0.3968 - val_mae: 0.3870 - val_mse: 0.6454 - learning_rate: 3.1250e-05\n",
      "Epoch 49/70\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3307 - mae: 0.3210 - mse: 0.2511\n",
      "Epoch 49: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.3307 - mae: 0.3210 - mse: 0.2515 - val_loss: 0.4038 - val_mae: 0.3940 - val_mse: 0.6330 - learning_rate: 3.1250e-05\n",
      "Epoch 50/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3317 - mae: 0.3220 - mse: 0.2529\n",
      "Epoch 50: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3314 - mae: 0.3217 - mse: 0.2513 - val_loss: 0.3984 - val_mae: 0.3887 - val_mse: 0.6391 - learning_rate: 3.1250e-05\n",
      "Epoch 51/70\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3287 - mae: 0.3190 - mse: 0.2457\n",
      "Epoch 51: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3299 - mae: 0.3202 - mse: 0.2487 - val_loss: 0.3975 - val_mae: 0.3878 - val_mse: 0.6351 - learning_rate: 3.1250e-05\n",
      "Epoch 52/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3308 - mae: 0.3211 - mse: 0.2531\n",
      "Epoch 52: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3312 - mae: 0.3215 - mse: 0.2528 - val_loss: 0.3967 - val_mae: 0.3870 - val_mse: 0.6293 - learning_rate: 3.1250e-05\n",
      "Epoch 53/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3285 - mae: 0.3188 - mse: 0.2495\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 53: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3288 - mae: 0.3191 - mse: 0.2484 - val_loss: 0.3991 - val_mae: 0.3895 - val_mse: 0.6358 - learning_rate: 3.1250e-05\n",
      "Epoch 54/70\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3294 - mae: 0.3198 - mse: 0.2481\n",
      "Epoch 54: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3294 - mae: 0.3198 - mse: 0.2490 - val_loss: 0.3951 - val_mae: 0.3855 - val_mse: 0.6275 - learning_rate: 1.5625e-05\n",
      "Epoch 55/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3303 - mae: 0.3207 - mse: 0.2508\n",
      "Epoch 55: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3304 - mae: 0.3208 - mse: 0.2498 - val_loss: 0.4002 - val_mae: 0.3906 - val_mse: 0.6320 - learning_rate: 1.5625e-05\n",
      "Epoch 56/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3293 - mae: 0.3197 - mse: 0.2479\n",
      "Epoch 56: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3294 - mae: 0.3199 - mse: 0.2475 - val_loss: 0.3960 - val_mae: 0.3864 - val_mse: 0.6284 - learning_rate: 1.5625e-05\n",
      "Epoch 57/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3285 - mae: 0.3189 - mse: 0.2491\n",
      "Epoch 57: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3295 - mae: 0.3199 - mse: 0.2507 - val_loss: 0.3987 - val_mae: 0.3892 - val_mse: 0.6302 - learning_rate: 1.5625e-05\n",
      "Epoch 58/70\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3297 - mae: 0.3201 - mse: 0.2500\n",
      "Epoch 58: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3294 - mae: 0.3198 - mse: 0.2484 - val_loss: 0.3982 - val_mae: 0.3886 - val_mse: 0.6283 - learning_rate: 1.5625e-05\n",
      "Epoch 59/70\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3298 - mae: 0.3202 - mse: 0.2503\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 59: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.3294 - mae: 0.3198 - mse: 0.2491 - val_loss: 0.3955 - val_mae: 0.3860 - val_mse: 0.6249 - learning_rate: 1.5625e-05\n",
      "Epoch 60/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3302 - mae: 0.3207 - mse: 0.2511\n",
      "Epoch 60: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.3293 - mae: 0.3197 - mse: 0.2489 - val_loss: 0.3944 - val_mae: 0.3849 - val_mse: 0.6219 - learning_rate: 7.8125e-06\n",
      "Epoch 61/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3291 - mae: 0.3195 - mse: 0.2483\n",
      "Epoch 61: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3295 - mae: 0.3200 - mse: 0.2486 - val_loss: 0.3940 - val_mae: 0.3844 - val_mse: 0.6216 - learning_rate: 7.8125e-06\n",
      "Epoch 62/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3292 - mae: 0.3197 - mse: 0.2480\n",
      "Epoch 62: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.3285 - mae: 0.3189 - mse: 0.2473 - val_loss: 0.3944 - val_mae: 0.3849 - val_mse: 0.6235 - learning_rate: 7.8125e-06\n",
      "Epoch 63/70\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3280 - mae: 0.3185 - mse: 0.2460\n",
      "Epoch 63: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.3286 - mae: 0.3191 - mse: 0.2467 - val_loss: 0.3970 - val_mae: 0.3875 - val_mse: 0.6282 - learning_rate: 7.8125e-06\n",
      "Epoch 64/70\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3289 - mae: 0.3194 - mse: 0.2485\n",
      "Epoch 64: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3284 - mae: 0.3189 - mse: 0.2476 - val_loss: 0.3911 - val_mae: 0.3816 - val_mse: 0.6191 - learning_rate: 7.8125e-06\n",
      "Epoch 65/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3290 - mae: 0.3195 - mse: 0.2520\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 65: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.3284 - mae: 0.3189 - mse: 0.2487 - val_loss: 0.3907 - val_mae: 0.3812 - val_mse: 0.6203 - learning_rate: 7.8125e-06\n",
      "Epoch 66/70\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3289 - mae: 0.3194 - mse: 0.2472\n",
      "Epoch 66: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.3296 - mae: 0.3201 - mse: 0.2488 - val_loss: 0.3916 - val_mae: 0.3821 - val_mse: 0.6203 - learning_rate: 3.9063e-06\n",
      "Epoch 67/70\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3283 - mae: 0.3188 - mse: 0.2475\n",
      "Epoch 67: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.3280 - mae: 0.3185 - mse: 0.2469 - val_loss: 0.3938 - val_mae: 0.3843 - val_mse: 0.6215 - learning_rate: 3.9063e-06\n",
      "Epoch 68/70\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3290 - mae: 0.3195 - mse: 0.2480\n",
      "Epoch 68: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.3281 - mae: 0.3186 - mse: 0.2469 - val_loss: 0.3951 - val_mae: 0.3856 - val_mse: 0.6211 - learning_rate: 3.9063e-06\n",
      "Epoch 69/70\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3280 - mae: 0.3185 - mse: 0.2454\n",
      "Epoch 69: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3292 - mae: 0.3197 - mse: 0.2483 - val_loss: 0.3927 - val_mae: 0.3832 - val_mse: 0.6188 - learning_rate: 3.9063e-06\n",
      "Epoch 70/70\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3293 - mae: 0.3198 - mse: 0.2497\n",
      "Epoch 70: val_mae did not improve from 0.28246\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.3288 - mae: 0.3193 - mse: 0.2482 - val_loss: 0.3938 - val_mae: 0.3843 - val_mse: 0.6201 - learning_rate: 3.9063e-06\n",
      "Restoring model weights from the end of the best epoch: 65.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_norm,\n",
    "    y_train_log,\n",
    "    batch_size=512,\n",
    "    epochs=50,\n",
    "    validation_data=(X_valid_norm, y_val_log),\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1babe2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3087/3087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
      "Validation MAE: 0.38123\n"
     ]
    }
   ],
   "source": [
    "val_predictions = model.predict(X_valid_norm).ravel()\n",
    "mae = mean_absolute_error(y_val_log, val_predictions)\n",
    "\n",
    "print(f\"Validation MAE: {mae:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ed0938b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"engie_dnn_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
